

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Outlier Detection &#8212; Applied Machine Learning in Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Model Evaluation" href="../04-model-evaluation/index.html" />
    <link rel="prev" title="Clustering and Mixture Models" href="02-clustering-mixture-models.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Applied Machine Learning in Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">1. Welcome</a>
  </li>
  <li class="">
    <a href="../00-introduction/00-introduction.html">2. Introduction</a>
  </li>
  <li class="">
    <a href="../01-ml-workflow/00-ml-workflow.html">3. The Machine Learning Workflow</a>
  </li>
  <li class="">
    <a href="../02-supervised-learning/index.html">4. Supervised Learning Algorithms</a>
  </li>
  <li class="active">
    <a href="index.html">5. Unsupervised Learning Algorithms</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="01-matrix-factorization-dimensionality-reduction.html">5.1 Matrix Factorization and Dimensionality Reduction</a>
    </li>
    <li class="">
      <a href="02-clustering-mixture-models.html">5.2 Clustering and Mixture Models</a>
    </li>
    <li class="active">
      <a href="">5.3 Outlier Detection</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../04-model-evaluation/index.html">6. Model Evaluation</a>
  </li>
  <li class="">
    <a href="../05-advanced-topics/index.html">7. Advanced Topics</a>
  </li>
</ul>
</nav>
<p class="navbar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/03-unsupervised-learning/03-outlier-detection.ipynb.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/03-unsupervised-learning/03-outlier-detection.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="../_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#applications" class="nav-link">Applications</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#basic-idea" class="nav-link">Basic idea</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#elliptic-envelope" class="nav-link">Elliptic Envelope</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#failure-case-non-gaussian-data" class="nav-link">Failure-case: Non-Gaussian Data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#kernel-density" class="nav-link">Kernel Density</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#kernel-bandwidth" class="nav-link">Kernel Bandwidth</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#one-class-svm" class="nav-link">One Class SVM</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#isolation-forests" class="nav-link">Isolation Forests</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#building-the-forest" class="nav-link">Building the forest</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#other-density-based-models" class="nav-link">Other density based-models</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#summary" class="nav-link">Summary</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#id1" class="nav-link">Outlier Detection</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="outlier-detection">
<h1>Outlier Detection<a class="headerlink" href="#outlier-detection" title="Permalink to this headline">¶</a></h1>
<p>The idea in outlier detection is to find points that are
different. There are two quite related kinds of outlier
detection summarized under outlier detection. There’s
outlier detection and novelty detection.</p>
<p>#Motivation
.padding-top[
.left-column[
<img alt=":scale 100%" src="../_images/outlier_detection.png" />
]</p>
<p>.right-column[
<img alt=":scale 100%" src="../_images/novelty_detection.png" />
]
]</p>
<p>Both are unsupervised methods. The idea is to find things
that are different. In outlier detection, usually, your
training dataset also contains outliers which makes it a bit
dirty, while in novelty detection, you get a dataset and
then, later on, someone gives you new data and asks you what
is new here. So in novelty detection, your dataset would be
clean.</p>
<p>But in both, you want to identify something that’s sort of
different from the standard distribution. Only, in the
outlier detection case, there are already different samples
in your training dataset.</p>
<p>This is one of the rigidly few unsupervised problems that
are pretty heavily used in practice.</p>
<ul class="simple">
<li><p>Find points that are “different” within the training set (and in the future).</p></li>
<li><p>“Novelty detection” - no outliers in the training set.</p></li>
<li><p>Outliers are not labeled! (otherwise it’s just imbalanced classification)</p></li>
<li><p>Often outlier detection and novelty detection used interchangeably in practice.</p></li>
</ul>
<div class="section" id="applications">
<h2>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Fraud detection (credit cards, click fraud, …)</p></li>
<li><p>Network failure detection</p></li>
<li><p>Intrusion detection in networks</p></li>
<li><p>Defect detection (engineering etc…)</p></li>
<li><p>News? Intelligence?</p></li>
<li><p>usual assumption: all outliers are different in a different way.</p></li>
<li><p>Often people use classification datasets for outlier detection:
that’s a bit strange. See homework results.</p></li>
</ul>
</div>
<div class="section" id="basic-idea">
<h2>Basic idea<a class="headerlink" href="#basic-idea" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Model data distribution <span class="math notranslate nohighlight">\(p(X)\)</span></p></li>
</ul>
<p>–</p>
<ul class="simple">
<li><p>Outlier: <span class="math notranslate nohighlight">\(p(X) 
&lt;
\varepsilon\)</span></p></li>
</ul>
<p>–</p>
<ul class="simple">
<li><p>For outlier detection: be robust in modelling <span class="math notranslate nohighlight">\(p(X)\)</span></p></li>
</ul>
<p>The main idea is, you model your data distribution, p(X).
And then you look at the data points that are unlikely under
the model. So if it’s unlikely under the model, then it’s
probably an outlier.</p>
<p>If you’re doing outlier detection that means your sample is
going to be contaminated. So they’re outliers in the dataset
X already if that is the case, you want to be robust in
modeling p(X), so you want to model p(X) in a way that is
robust to outliers.</p>
<p>Both of these tasks are generally ill-defined. So unless you
actually know the real data distribution, how good something
does is hard to measure. Usually, you don’t have ground
truth of what the outliers are if you have the ground truth
what the outliers are, you could just do an imbalance
classification task.</p>
<p>So similar to clustering, what we’re doing here is building
a model, trying to find some outliers, and then check if
they’re actually outliers. If we are satisfied with the
things that our model finds, then we can put into
production. But there’s no guarantee that it’s going to find
like x fraction of the outliers and since we don’t have
labeled data, usually, we can’t really measure our recall.
We won’t ever know about the samples that we didn’t find.</p>
<p>So maybe with respect to the homework and in the homework
actually have ground truth data. And it’s similar to the
clustering setting, where researchers are basically cheating
and evaluating methods that are unsupervised in a supervised
manner. So once you have ground truth label, you can
evaluate your outlier detection, using, for example, AUC,
which is what you’re going to do your homework.</p>
<p>But in a real-world setting, if you had the labels, you
would never use outlier detection.</p>
<p>Again, similar to clustering, what makes an outlier in a
particular dataset is ill-defined. So depends on the
application, what do you want to consider an outlier or not.
So in the homework, it’s ill and healthy, and the ill people
are the outliers. But it could also be that the people that
are much older and everybody else are the outliers.</p>
<p>If there’s sort of a very clear density model, and so you
don’t know what the density of the data is supposed to look
like and then, you know, things that don’t share this
density, then you can sort of define this. But usually you
don’t know what the density supposed to look like and so
there’s no clearly defined notion of what is an outlier.
Similarly only, there’s no clearly defined solution of what
should be a cluster.</p>
<p>So we’re going to talk through a couple of different
algorithms that make different assumptions about what makes
a data point an outlier. So here, I said, we start usually
with a data distribution p(X).</p>
<ul class="simple">
<li><p>Task is generally ill-defined (unless you know the
real data distribution).</p></li>
<li><p>Task is generally ill-defined (unless you know the
real data distribution).</p></li>
</ul>
<p>#Elliptic Envelope</p>
<div class="math notranslate nohighlight">
\[p(X) = \mathcal{N}(\mu, \Sigma)\]</div>
<p>.center[
<img alt=":scale 60%" src="../_images/elliptic_envelope.png" />
]</p>
<p>This leads to the elliptic envelope outlier detection.
Basically, it fits a Gaussian into the data, and then it
looks at the points that are not fit well by the Gaussians
and those points are the outliers. Since this is meant for
the outlier detection task, what we’re trying to do is
actually trying to find a robust estimate of the mean and
covariance matrix so that we can tolerate some outliers in
the training dataset, and still sort of recover the real
covariance matrix.</p>
<p>In this illustration, the black points, inliers, are what
you expect the data to look like and the outlier
distribution is plotted in red.</p>
<p>They overlap, so usually in unsupervised methods, you will
never label any of these red points as outliers but we could
try to figure out that these points here are outliers.</p>
<p>The way that elliptic envelope works are that it finds a
robust version of the variance matrix. Basically, it finds
the covariance matrix with the smallest determinant that
still covers a large portion of the data.</p>
<p>In most outlier detection methods, you have to specify how
many outliers you expect. So here, let’s say we specify 10%
of the data to be outliers, then it will try to construct
the covariance matrix that covers 90% of the data, but holds
the lowest possible determinant.</p>
<p>If you do this, you get the red dotted circles, which are
the contours covariance fitted with the robust estimate and
the blue circles are the covariance fitted with the maximum
likelihood estimates, using all the data.</p>
<p>Obviously, these outliers can disturb the covariance matrix
and so the blue is sort of too thick in one direction
whereas the red is not. So now, if you have this red model,
you can basically say, all the data lies within these two
standard deviations and so everything outside here is an
outlier.</p>
<p>Fit robust covariance matrix and mean
FIXME add slide on Covariance: Minimum Covariance Determination (MinCovDet)</p>
</div>
<div class="section" id="elliptic-envelope">
<h2>Elliptic Envelope<a class="headerlink" href="#elliptic-envelope" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Preprocessing with PCA might help sometimes.</p></li>
</ul>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>from sklearn.covariance import EllipticEnvelope
ee = EllipticEnvelope(contamination=.1).fit(X)
pred = ee.predict(X)
print(pred)
print(np.mean(pred == -1))
```]

.smaller[
```python
[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
 -1  1  1  1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1  1]
0.104

```]



The way we do this in scikit-learn. The covariance module
has all the robust covariance methods. As I said, you have
to specify the contamination, which is how many outliers do
you expect. Here, I set it to 10%.

If I predict I get 1s and -1s. All the outlier models in
scikit-learn use 1 for inliers and -1 to outliers.

The mean of the prediction tells me that about 10% of the
training data was labeled as an outlier, which is what we
would expect, given that we set it as 10%.  You could also
get a continuous score saying how much of an outlier is each
point with the score samples methods.

Here, in the elliptic envelope, contamination parameter
changes how the model is fit, for some other models, this
will actually only change the threshold. It’s important here
to have the right contamination parameters for the right
covariance fit.

For real-world model, set it based on what your expectations
are.
</pre></div>
</div>
</div>
<div class="section" id="failure-case-non-gaussian-data">
<h2>Failure-case: Non-Gaussian Data<a class="headerlink" href="#failure-case-non-gaussian-data" title="Permalink to this headline">¶</a></h2>
<p>.center[
<img alt=":scale 80%" src="../_images/elliptic_envelope_plot.png" />
]</p>
<p>If the data is not Gaussian, we get this.</p>
<p>In this dataset, my intuition was that the isolated three
points are the outliers and the rest are the normal data.
Since the data is non-Gaussian, it gives you 10% as outliers
that are furthest away from the mean. And this is not what I
wanted at all.</p>
<p>So if your data is very non-Gaussian, then the method will
not clearly work well.</p>
<p>Now, we could obviously use a more complicated density
model. So we talked about Gaussian mixture models, we could
use a Gaussian mixture model. Instead of fitting a single
Gaussian, we could try to fit multiple Gaussian. If you just
use the Gaussian mixture models in scikit-learn, they will
not do a robust fit, so that might make more sense in the
novelty detection than in the outlier detection sense
because it will try to fit all of the data. You can still
try to do it on the outlier detection task and just fit, so
if I fit three Gaussians here, it’ll probably give me the
right outliers. But then again, I need to know what the
number of components is for my GMM, for this to work well.</p>
<p>So I still to make the assumptions about what the density
is.</p>
<p>Another approach is instead of having a parametric density
model like this, we can do a non-parametric density model
like a kernel density estimate.</p>
<p>Could do mixtures of gaussians obviously!</p>
</div>
<div class="section" id="kernel-density">
<h2>Kernel Density<a class="headerlink" href="#kernel-density" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 80%" src="../_images/kde_vs_histogram.png" /></p>
<p>KDE is a most simple non-parametric estimate for probability
distributions. The ticks at the bottom in the left plot are
data points. One way to visualize the distribution is to do
a histogram.</p>
<p>For the KDE estimate in the right, we put a small Gaussian
blob around each data point. So here, each data point here
at the bottom corresponds to one of these Gaussians and then
we just sum them all up and this gives you sort of this
smooth density here.</p>
<p>So this a little bit like a GMM where we have as many
components as data points. You could also use other kernels.</p>
<p>The word kernel here means slightly different than in SVMs.
Kernel here means kernel in the sense of signal processing.
So another commonly used kernel here is the top hat kernel,
which is a kernel in the signal processing sense but it’s
not a kernel in the support vector machine sense, the
Gaussian kernel was the kernel in both senses.</p>
<p>A kernel can mean a lot of different things. And here, it
means basically windowing function. And so any windowing
function would work for this, you kind of put a little bit
of probability math around each data point.</p>
<p>An obvious problem with this is that you need to pick the
bandwidth.</p>
<ul class="simple">
<li><p>Non-parametric density model</p></li>
<li><p>Gaussian blob on each data point</p></li>
<li><p>Doesn’t work well in high dimensions</p></li>
</ul>
</div>
<div class="section" id="kernel-bandwidth">
<h2>Kernel Bandwidth<a class="headerlink" href="#kernel-bandwidth" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 50%" src="../_images/kde_bandwidth.png" /></p>
<p>So depending on what bandwidth you pick, you can either over
smooth or under smooth the data. Here, in red, you’ve picked
too small of bandwidth while in green, you’ve picked two
large of bandwidth and black is probably a decent bandwidth.</p>
<p>Again, this is an unsupervised problem. So it’s very hard to
do this. You can actually use cross validation to adjust the
bandwidth. So you can look at what’s the score of the held
out data.</p>
<p>This is also not a robust estimate. So if you have outliers
in your data, the outliers in your data might influence your
estimate.</p>
<p>The other problem with this is that KDDs don’t work in
higher dimensions. You can obviously not only do this
1-dimension, but you can also do this in any number of
dimensions. But here, you get the curse of dimensionality.
Basically, if you have higher dimensional space, you need
more and more data points to actually fill the space with
these small Gaussian blobs. If you would want to do a
histogram, in like 10 dimensions, and you don’t have enough
data, then most of the histogram cells will be empty. And
here, this is only like a smooth version of the histogram so
it has the same problem.</p>
<p>So if your space is in high dimensional, most of the space
will be empty and this is not going to work very well.</p>
<ul class="simple">
<li><p>Need to adjust kernel bandwidth</p></li>
<li><p>Unsupervised model, so how to pick kernel bandwidth?</p></li>
<li><p>cross-validation can be used to pick the bandwidth, but if there’s outliers in the training
data, could go wrong?</p></li>
</ul>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>kde = KernelDensity(bandwidth=3)
kde.fit(X_train_noise)
pred = kde.score_samples(X_train_noise)
pred = (pred &gt; np.percentile(pred, 10)).astype(int)
```]

.center[
![:scale 70%](images/kernel_density_bw3.png)
]


If your space is low dimensional, and you can plot it, it
might work nicely. So here, I might have used the
cross-validation to find out the bandwidth of 3 is good. And
then I can look at the scores. So here, KDE is not an
outlier detection method in scikit-learn, but I can use it
as an outlier detection method by just looking at score
samples, which are the log probabilities of all the data
points under this probability model. And I say that
everything that&#39;s higher than the 10th percentile is an
inlier.

So basically, now I label 10% of the data as outliers and I
actually get the right three points that I wanted and a
couple more points. Obviously, I get more points, because I
told them I want 10% of my data to be outliers.

So this is a really is a very simple method. But it doesn’t
work well in higher dimensions and it gets very slow since
you have a lot of these kernels that you need to evaluate.
So you need to compute the distance between all pairs of
points mostly.
</pre></div>
</div>
</div>
<div class="section" id="one-class-svm">
<h2>One Class SVM<a class="headerlink" href="#one-class-svm" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Also uses Gaussian kernel to cover data</p></li>
<li><p>Only select support vectors (not all points)</p></li>
<li><p>Specify outlier ratio (contamination) via nu</p></li>
</ul>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>from sklearn.svm import OneClassSVM
scaler = StandardScaler()
X_train_noise_scaled = scaler.fit_transform(X_train_noise)
oneclass = OneClassSVM(nu=.1).fit(X_train_noise_scaled)
pred = oneclass.predict(X_train_noise_scaled)
```]



A more sophisticated variant of this is the one class SVM.
This also uses Gaussian kernels to basically cover the data.
But it selects only support vectors, not all points as basis
points. You get a similar function, in KDE.

But the density function is supported only by some support
vectors. Again, you need to specify the bandwidth parameter
gamma. So this only makes sense with an RVF kernel. It’s
quite similar to what KDE does, but only, it selects support
vectors and does it in a more robust way.

You also have to set the number of outliers you expect as
nu. Again, nu is part of the optimization process. So
setting the outlier fraction differently will change how the
models fit.


- Need to adjust kernel bandwidth
- nu is &quot;training mistakes&quot;

+++
.center[
![:scale 80%](images/one_class_svm_plot.png)
]



So here, this was with a particular setting of gamma, and
you can see that it seems like a somewhat reasonable model.
If I made gamma a little bit smaller, it would probably have
found the right points. But here, it&#39;s even harder to adjust
the gamma parameter because there&#39;s no way to really do it.
So for KDE, I can do cross-validation to see how good of a
probability model this is, while the SVM doesn&#39;t have a
probability model. So I can&#39;t do cross-validation or
anything. So I just need to pick gamma in some way that
makes sense to me, which is not great.

If you can visualize data, obviously, that helps. But in
higher dimensions, you need to look at projections or other
things to see how to set gamma. So in a sense, is also sort
of a non-parametric density estimate. But it doesn&#39;t really
have a probabilistic model.
</pre></div>
</div>
</div>
<div class="section" id="isolation-forests">
<h2>Isolation Forests<a class="headerlink" href="#isolation-forests" title="Permalink to this headline">¶</a></h2>
<p>The final model I want to talk about is also a
non-parametric estimate that also doesn’t have a probability
model and it’s called isolation forest</p>
<p>By far, it’s my favorite since it has no parameters to tune.</p>
<p>#Idea</p>
<ul class="simple">
<li><p>Outliers are easy to isolate from the rest</p></li>
</ul>
<p>.center[
<img alt=":scale 80%" src="../_images/isolation_forests.png" />
]</p>
<p>So the idea of isolation forest is that if you build a
random tree over a dataset, then if you want to figure out
how easy is it to split up a particular point, it’s much
easier to split up a point that’s an outlier, that’s on the
outside of the data than a point that’s like somewhere where
the data is very dense.</p>
<p>The idea is that you build many completely random trees,
it’s complete unsupervised, so it just keeps splitting the
data in some way and we look at how deep do we need to go to
isolate a data point from the other data points.</p>
<p>If on average, we have to go very deep into the tree, it’s
probably if some of our data is dense, it’s not an outlier.
So on average, if we split off the point very early, it’s
probably an outlier.</p>
<ul class="simple">
<li><p>Measure as Path length!</p></li>
</ul>
<p>.left-column[
<img alt=":scale 100%" src="../_images/isolation_forests.png" />
]</p>
<p>.right-column[
<img alt=":scale 100%" src="../_images/avgpathlen_numtrees.png" />
]</p>
<p>If you add more and more completely random trees, you get a
relatively stable score that tells you is it an outlier or
is it an outlier. You can think of this as sort of trying to
model the density of the data. But there’s no probabilistic
model here.</p>
<p>X1 has over 1000 trees, you need a very long path line so
you go very deep into a tree before it’s isolated from the
other point. That means it’s in a very dense region.
Whereas, X0, on average is split up quite early from the
rest of data points so it’s probably an outlier. So
basically, if you’re on the outside of the data, no matter
what feature is picked, you’re likely to be split off, given
that you’re an outlier with respect to any of these
features.</p>
<p>#Normalizing the Path Length</p>
<p>Average path length of unsuccessful search in Binary Search Tree:</p>
<div class="math notranslate nohighlight">
\[ c(n) = 2H(n-1) - \left(\frac{2(n-1)}{n}\right) \text{  (H = Harmonic number)}\]</div>
<div class="math notranslate nohighlight">
\[ s(x,n) = 2^{-\frac{E(h(x))}{c(n)}} \text{   (h = depth in tree)}\]</div>
<ul class="simple">
<li><p>s &lt; 0.5 : definite inlier</p></li>
<li><p>s close to 1: outlier</p></li>
</ul>
<p>So to make this more coherent, we need to normalize the path
lines. And so depending on how many data points there are,
you expect to go deeper to the tree to separate something.
And so you can calculate what the average path length of an
unsuccessful search is in the binary tree, which is similar
to trying to isolate a point, and you can compute this
number.</p>
<p>And the score that we actually compute, the outlier score is
2 to the minus average path length over all the trees
divided by the average path lengths for an unsuccessful
search in binary trees. So this only depends on n which is
the number of data points. So basically, we are only
normalizing the score to make sense independent of the
dataset size.</p>
<p>If this score is smaller than 0.5 then definitely you’re an
inlier. If it’s closer to 1, it’s an outlier.</p>
<p>Basically, the way you determine outliers is by threshold
the score. So here, setting the number of expected outliers
doesn’t change the algorithm at all, it only changes the
threshold for this core function. So here, picking the
number of outliers in advance is not as important.</p>
</div>
<div class="section" id="building-the-forest">
<h2>Building the forest<a class="headerlink" href="#building-the-forest" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Subsample dataset for each tree</p></li>
<li><p>Default sample size of 256 works surprisingly well</p></li>
<li><p>Stop growing tree at depth log_2(sample size) – so 8</p></li>
<li><p>No bootstrapping</p></li>
<li><p>More trees are better – default 100</p></li>
<li><p>Need to specify contamination rate</p></li>
</ul>
<p>It has no parameters, it’s quite simple to do this. So what
we’re doing is actually we subsample the dataset for each
tree and we picked 256 samples. The default value of 256
samples always works, no matter what the dataset size is.
And we stopped growing the tree at depth log_2 (sample
size), which is 8.</p>
<p>So you repeatedly draw, without replacement, 256 samples
from your data and grow trees of depth 8 and then you look
at the average path length to isolate a point.</p>
<p>Obviously, as with all random forest, more trees are better
but the default in scikit-learn is 100.</p>
<p>In principle, these are free parameters of the algorithm,
like, how much to subsample for each tree, and how to prune
each tree. But people don’t tune these parameters and it
just works well.</p>
<p>The contamination rate only picks the threshold on this
final score.</p>
<p>FIXME all the text</p>
<p>.center[<img alt=":scale 90%" src="../_images/building_forest_1.png" />]</p>
<p>Here is what the algorithm produces and it worked as good as
I thought.</p>
<p>Remember, this is a toy dataset. It doesn’t really tell you
that much about how works in the real world.</p>
<p>.center[<img alt=":scale 90%" src="../_images/building_forest_2.png" />]</p>
<p>Here, I plotted the score for each data point. You could do
this for data models too. Here, since it’s tree-based, it’s
not nice and smooth as it is for support vector machine or
the KDE. I didn’t have to tune any kernel bandwidth or
anything and so that’s kind of nice.</p>
<p>Again, it also depends on what your assumptions are about
outliers. This will not work very well for the homework. And
you can think about why this does not work very well from
your homework.</p>
</div>
<div class="section" id="other-density-based-models">
<h2>Other density based-models<a class="headerlink" href="#other-density-based-models" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>PCA</p></li>
<li><p>GMMs</p></li>
<li><p>Robust PCA (not in sklearn :-()</p></li>
<li><p>Any other probabilistic model - “robust” is better.</p></li>
</ul>
<p>You can use other density based models. You can use just PCA which is also like a higher dimensional Gaussian model in some sense, where you drop some of the directions.</p>
<p>You can use GMMs.</p>
<p>There’s a robust variant of PCA that is, unfortunately, not
on scikit-learn.</p>
<p>You can use any probabilistic model that you want. But you
need to think about if the model is appropriate for the data
that you’re trying to model. And if you expect there’s a lot
of outliers in your training dataset already, then you might
need to think about how to make the model robust.</p>
<p>So PCA is not robust, while robust PCA is robust. And so if
you have very big outliers in your dataset, it will skew
your PCA results and so that might not work as well.</p>
<p>robust only needed for outlier detection, not novelty detection.</p>
<p>.center[
<img alt=":scale 60%" src="../_images/other_density_models_1.png" />
]</p>
<p>.center[
<img alt=":scale 60%" src="../_images/other_density_models_2.png" />
]</p>
<p>.center[
<img alt=":scale 60%" src="../_images/other_density_models_3.png" />
]</p>
<p>Here is a comparison of the three of the four models that we
talked about. So here, we’re looking at isolation forest,
one class SVM, and robust covariance.</p>
<p>Basically, the robots covariance works perfectly for
isotropic Gaussian, because that’s what it fits. If you have
multiple Gaussians it kind of breaks down. So if they’re
close enough together, maybe it makes sense to model them as
joint Gaussian. But if you put them further apart,
basically, it will change the covariance shape and so it
will have a bad model of your data.</p>
<p>So the isolation forest does kind of reasonably well in all
cases. I mean, this is a 2D dataset and so it can just find
dense regions without a problem. Whereas the one class SVM,
gives slightly strange results, probably because it picked
some support vectors to cover the data.</p>
<p>Ideally, the one class SVM is supposed to be robust to
contamination in the training set, but as we can see, it’s
not that robust to contamination. The one clause SVM might
work better when you have a clean training dataset.</p>
<p>There’s no definition of true outliers, obviously. But here,
we have drawn very densely from either one or two Gaussian
models, the inliers are white and then we have random
uniform over this whole square some outliers.</p>
<p>The idea is basically, there’s 3 different distribution that
the data is drawn from. There’s like some Gaussian points
and some points that are just uniform. And you want to
isolate the very dense points from the uniform that not very
dense points.</p>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Isolation Forest works great!</p></li>
<li><p>Density models are great if they are correct.</p></li>
<li><p>Estimating bandwidth can be tricky in the
unsupervised setting.</p></li>
<li><p>Validation of results often requires manual inspection.</p></li>
</ul>
<p>As with all unsupervised methods, for outlier detection,
validating the model and tuning the parameters are really
hard. So the more your model depends on parameters, like the
one class SVM depends a lot on parameters, it’s just very
tricky to do that.</p>
<p>As with the clustering, validation often means looking into
the data, looking at single data points, why are they
outliers and trying to interpret the results. Because if you
have two labels, why don’t you learn a classifier.</p>
<p>One possible approach that I didn’t talk about is if you
have a big dataset that’s not labeled, you can run an
outlier detection algorithm, you can find like 10% most
outlier things according to your algorithm, you can confirm
manually whether they are outliers or not and then you could
run a classifier. It depends a little bit on whether the
outliers are all outliers in a similar way or outliers in
different ways. So if all your outliers are outliers in a
different way, then running a classifier will actually not
work. So in that setting, you might actually be better off
with an outlier detection method.</p>
<p>Even if you have labels, if all of your outliers are
outliers in a very different way, it might be better to just
build the model off the non-outlier data and then call
everything else that’s an outlier instead of trying to learn
a classifier. If there’s no dense region of outliers, then
you can’t learn a classifier for that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span> <span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span><span class="p">,</span> <span class="n">StandardScaler</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">matplotlib.offsetbox</span> <span class="kn">import</span> <span class="n">OffsetImage</span><span class="p">,</span> <span class="n">AnnotationBbox</span>


</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_mldata</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s2">&quot;MNIST original&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="stderr docutils container">
<pre class="stderr literal-block">/home/andy/checkout/scikit-learn/sklearn/utils/deprecation.py:76: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.
  warnings.warn(msg, category=DeprecationWarning)
/home/andy/checkout/scikit-learn/sklearn/utils/deprecation.py:76: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.
  warnings.warn(msg, category=DeprecationWarning)
</pre>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ConnectionResetError</span><span class="g g-Whitespace">                      </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-3-8a029c5f792a&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_mldata</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s2">&quot;MNIST original&quot;</span><span class="p">)</span>

<span class="nn">~/checkout/scikit-learn/sklearn/utils/deprecation.py</span> in <span class="ni">wrapped</span><span class="nt">(*args, **kwargs)</span>
<span class="g g-Whitespace">     </span><span class="mi">75</span>         <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span>             <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">DeprecationWarning</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">77</span>             <span class="k">return</span> <span class="n">fun</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">78</span> 
<span class="g g-Whitespace">     </span><span class="mi">79</span>         <span class="n">wrapped</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_doc</span><span class="p">(</span><span class="n">wrapped</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>

<span class="nn">~/checkout/scikit-learn/sklearn/datasets/mldata.py</span> in <span class="ni">fetch_mldata</span><span class="nt">(dataname, target_name, data_name, transpose_data, data_home)</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span>         <span class="n">urlname</span> <span class="o">=</span> <span class="n">MLDATA_BASE_URL</span> <span class="o">%</span> <span class="n">quote</span><span class="p">(</span><span class="n">dataname</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">125</span>         <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">126</span>             <span class="n">mldata_url</span> <span class="o">=</span> <span class="n">urlopen</span><span class="p">(</span><span class="n">urlname</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">127</span>         <span class="k">except</span> <span class="n">HTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">128</span>             <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">code</span> <span class="o">==</span> <span class="mi">404</span><span class="p">:</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">urlopen</span><span class="nt">(url, data, timeout, cafile, capath, cadefault, context)</span>
<span class="g g-Whitespace">    </span><span class="mi">220</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">221</span>         <span class="n">opener</span> <span class="o">=</span> <span class="n">_opener</span>
<span class="ne">--&gt; </span><span class="mi">222</span>     <span class="k">return</span> <span class="n">opener</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">timeout</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">223</span> 
<span class="g g-Whitespace">    </span><span class="mi">224</span> <span class="k">def</span> <span class="nf">install_opener</span><span class="p">(</span><span class="n">opener</span><span class="p">):</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">open</span><span class="nt">(self, fullurl, data, timeout)</span>
<span class="g g-Whitespace">    </span><span class="mi">523</span>             <span class="n">req</span> <span class="o">=</span> <span class="n">meth</span><span class="p">(</span><span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">524</span> 
<span class="ne">--&gt; </span><span class="mi">525</span>         <span class="n">response</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_open</span><span class="p">(</span><span class="n">req</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">526</span> 
<span class="g g-Whitespace">    </span><span class="mi">527</span>         <span class="c1"># post-process response</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">_open</span><span class="nt">(self, req, data)</span>
<span class="g g-Whitespace">    </span><span class="mi">541</span>         <span class="n">protocol</span> <span class="o">=</span> <span class="n">req</span><span class="o">.</span><span class="n">type</span>
<span class="g g-Whitespace">    </span><span class="mi">542</span>         <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_chain</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">handle_open</span><span class="p">,</span> <span class="n">protocol</span><span class="p">,</span> <span class="n">protocol</span> <span class="o">+</span>
<span class="ne">--&gt; </span><span class="mi">543</span>                                   <span class="s1">&#39;_open&#39;</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">544</span>         <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">545</span>             <span class="k">return</span> <span class="n">result</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">_call_chain</span><span class="nt">(self, chain, kind, meth_name, *args)</span>
<span class="g g-Whitespace">    </span><span class="mi">501</span>         <span class="k">for</span> <span class="n">handler</span> <span class="ow">in</span> <span class="n">handlers</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">502</span>             <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">handler</span><span class="p">,</span> <span class="n">meth_name</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">503</span>             <span class="n">result</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">504</span>             <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">505</span>                 <span class="k">return</span> <span class="n">result</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">http_open</span><span class="nt">(self, req)</span>
<span class="g g-Whitespace">   </span><span class="mi">1343</span> 
<span class="g g-Whitespace">   </span><span class="mi">1344</span>     <span class="k">def</span> <span class="nf">http_open</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">req</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1345</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_open</span><span class="p">(</span><span class="n">http</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">HTTPConnection</span><span class="p">,</span> <span class="n">req</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1346</span> 
<span class="g g-Whitespace">   </span><span class="mi">1347</span>     <span class="n">http_request</span> <span class="o">=</span> <span class="n">AbstractHTTPHandler</span><span class="o">.</span><span class="n">do_request_</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/urllib/request.py</span> in <span class="ni">do_open</span><span class="nt">(self, http_class, req, **http_conn_args)</span>
<span class="g g-Whitespace">   </span><span class="mi">1318</span>             <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span> <span class="c1"># timeout error</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span>                 <span class="k">raise</span> <span class="n">URLError</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
<span class="ne">-&gt; </span><span class="mi">1320</span>             <span class="n">r</span> <span class="o">=</span> <span class="n">h</span><span class="o">.</span><span class="n">getresponse</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1321</span>         <span class="k">except</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1322</span>             <span class="n">h</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/http/client.py</span> in <span class="ni">getresponse</span><span class="nt">(self)</span>
<span class="g g-Whitespace">   </span><span class="mi">1319</span>         <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1320</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1321</span>                 <span class="n">response</span><span class="o">.</span><span class="n">begin</span><span class="p">()</span>
<span class="g g-Whitespace">   </span><span class="mi">1322</span>             <span class="k">except</span> <span class="ne">ConnectionError</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1323</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/http/client.py</span> in <span class="ni">begin</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">294</span>         <span class="c1"># read until we get a non-100 response</span>
<span class="g g-Whitespace">    </span><span class="mi">295</span>         <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">296</span>             <span class="n">version</span><span class="p">,</span> <span class="n">status</span><span class="p">,</span> <span class="n">reason</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_read_status</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">297</span>             <span class="k">if</span> <span class="n">status</span> <span class="o">!=</span> <span class="n">CONTINUE</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">298</span>                 <span class="k">break</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/http/client.py</span> in <span class="ni">_read_status</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">255</span> 
<span class="g g-Whitespace">    </span><span class="mi">256</span>     <span class="k">def</span> <span class="nf">_read_status</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">257</span>         <span class="n">line</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">readline</span><span class="p">(</span><span class="n">_MAXLINE</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="s2">&quot;iso-8859-1&quot;</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">258</span>         <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">_MAXLINE</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">259</span>             <span class="k">raise</span> <span class="n">LineTooLong</span><span class="p">(</span><span class="s2">&quot;status line&quot;</span><span class="p">)</span>

<span class="nn">~/anaconda3/envs/py37/lib/python3.7/socket.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span>         <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">589</span>                 <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sock</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">590</span>             <span class="k">except</span> <span class="n">timeout</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">591</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_timeout_occurred</span> <span class="o">=</span> <span class="kc">True</span>

<span class="ne">ConnectionResetError</span>: [Errno 104] Connection reset by peer
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">data</span> <span class="o">/</span> <span class="mf">255.</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">NMF</span><span class="p">,</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>PCA(copy=True, iterated_power=&#39;auto&#39;, n_components=4, random_state=None,
  svd_solver=&#39;auto&#39;, tol=0.0, whiten=False)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_decomposition</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">components</span><span class="p">,</span> <span class="n">coef</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">):</span>
    <span class="n">image_shape</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>


    <span class="n">imagebox</span> <span class="o">=</span> <span class="n">OffsetImage</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">zoom</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">ab</span> <span class="o">=</span> <span class="n">AnnotationBbox</span><span class="p">(</span><span class="n">imagebox</span><span class="p">,</span> <span class="p">(</span><span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ab</span><span class="p">)</span>
    <span class="n">sorting</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">coef</span><span class="p">))[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
        <span class="n">imagebox</span> <span class="o">=</span> <span class="n">OffsetImage</span><span class="p">(</span><span class="n">components</span><span class="p">[</span><span class="n">sorting</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image_shape</span><span class="p">),</span> <span class="n">zoom</span><span class="o">=</span><span class="mf">5.</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>


        <span class="n">ab</span> <span class="o">=</span> <span class="n">AnnotationBbox</span><span class="p">(</span><span class="n">imagebox</span><span class="p">,</span> <span class="p">(</span><span class="o">.</span><span class="mi">3</span> <span class="o">+</span> <span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">),</span>
                          <span class="n">pad</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                          <span class="n">xycoords</span><span class="o">=</span><span class="s1">&#39;data&#39;</span>
                          <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">ab</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">.</span><span class="mi">18</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;</span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="n">sorting</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">.</span><span class="mi">165</span> <span class="o">+</span> <span class="o">.</span><span class="mi">202</span> <span class="o">*</span> <span class="n">i</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;+ </span><span class="si">{:.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="n">sorting</span><span class="p">[</span><span class="n">i</span><span class="p">]]),</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">})</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">.</span><span class="mi">96</span><span class="p">,</span> <span class="o">.</span><span class="mi">25</span><span class="p">,</span> <span class="s1">&#39;+ ...&#39;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">})</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">usetex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">.</span><span class="mi">13</span><span class="p">,</span> <span class="o">.</span><span class="mi">3</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;\approx&#39;</span><span class="p">,</span> <span class="n">fontdict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fontsize&#39;</span><span class="p">:</span> <span class="mi">30</span><span class="p">})</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_decomposition</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_decomposition</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">11000</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">11000</span><span class="p">:</span><span class="mi">11001</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03-outlier-detection_20_0.png" src="../_images/03-outlier-detection_20_0.png" />
<img alt="../_images/03-outlier-detection_20_1.png" src="../_images/03-outlier-detection_20_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nmf</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">nmf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>NMF(alpha=0.0, beta_loss=&#39;frobenius&#39;, init=None, l1_ratio=0.0, max_iter=200,
  n_components=20, random_state=None, shuffle=False, solver=&#39;cd&#39;,
  tol=0.0001, verbose=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_decomposition</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">nmf</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">nmf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plot_decomposition</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">11000</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">nmf</span><span class="o">.</span><span class="n">components_</span><span class="p">,</span> <span class="n">nmf</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">11000</span><span class="p">:</span><span class="mi">11001</span><span class="p">]</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03-outlier-detection_22_0.png" src="../_images/03-outlier-detection_22_0.png" />
<img alt="../_images/03-outlier-detection_22_1.png" src="../_images/03-outlier-detection_22_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nmf20</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">nmf20</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>NMF(alpha=0.0, beta_loss=&#39;frobenius&#39;, init=None, l1_ratio=0.0, max_iter=200,
  n_components=20, random_state=None, shuffle=False, solver=&#39;cd&#39;,
  tol=0.0001, verbose=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nmf5</span> <span class="o">=</span> <span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">nmf5</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>NMF(alpha=0.0, beta_loss=&#39;frobenius&#39;, init=None, l1_ratio=0.0, max_iter=200,
  n_components=5, random_state=None, shuffle=False, solver=&#39;cd&#39;,
  tol=0.0001, verbose=0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">comp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">nmf20</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">comp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03-outlier-detection_25_0.png" src="../_images/03-outlier-detection_25_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">comp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">nmf5</span><span class="o">.</span><span class="n">components_</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">comp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03-outlier-detection_26_0.png" src="../_images/03-outlier-detection_26_0.png" />
</div>
</div>
</div>
<div class="section" id="id1">
<h2>Outlier Detection<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=.</span><span class="mi">9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X_train_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))])</span>
<span class="n">y_train_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">y_train_noise</span><span class="p">))</span>
<span class="n">X_test_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))])</span>
<span class="n">y_test_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">y_test_noise</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Outlier Detection&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.text.Text at 0x7fc8daef46d8&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_28_1.png" src="../_images/03-outlier-detection_28_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=.</span><span class="mi">9</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X_train_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))])</span>
<span class="n">y_train_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">X_test_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))])</span>
<span class="n">y_test_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_test</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_test_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">y_test_noise</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Novelty Detection&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.text.Text at 0x7fc8dad73cc0&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_29_1.png" src="../_images/03-outlier-detection_29_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">EmpiricalCovariance</span><span class="p">,</span> <span class="n">MinCovDet</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">125</span>
<span class="n">n_outliers</span> <span class="o">=</span> <span class="mi">25</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># generate data</span>
<span class="n">gen_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">gen_cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">2.</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">gen_cov</span><span class="p">)</span>
<span class="c1"># add some outliers</span>
<span class="n">outliers_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
<span class="n">outliers_cov</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">7.</span>
<span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="n">n_outliers</span><span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_outliers</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">outliers_cov</span><span class="p">)</span>

<span class="c1"># fit a Minimum Covariance Determinant (MCD) robust estimator to data</span>
<span class="n">robust_cov</span> <span class="o">=</span> <span class="n">MinCovDet</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># compare estimators learnt from the full data set with true parameters</span>
<span class="n">emp_cov</span> <span class="o">=</span> <span class="n">EmpiricalCovariance</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Show data set</span>
<span class="n">subfig1</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">inlier_plot</span> <span class="o">=</span> <span class="n">subfig1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span>
                              <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;inliers&#39;</span><span class="p">)</span>
<span class="n">outlier_plot</span> <span class="o">=</span> <span class="n">subfig1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">][</span><span class="o">-</span><span class="n">n_outliers</span><span class="p">:],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="n">n_outliers</span><span class="p">:],</span>
                               <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;outliers&#39;</span><span class="p">)</span>
<span class="n">subfig1</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">subfig1</span><span class="o">.</span><span class="n">get_xlim</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">11.</span><span class="p">)</span>
<span class="n">subfig1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Mahalanobis distances of a contaminated data set:&quot;</span><span class="p">)</span>

<span class="c1"># Show contours of the distance functions</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">),</span>
                     <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">()[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">))</span>
<span class="n">zz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()]</span>

<span class="n">mahal_emp_cov</span> <span class="o">=</span> <span class="n">emp_cov</span><span class="o">.</span><span class="n">mahalanobis</span><span class="p">(</span><span class="n">zz</span><span class="p">)</span>
<span class="n">mahal_emp_cov</span> <span class="o">=</span> <span class="n">mahal_emp_cov</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">emp_cov_contour</span> <span class="o">=</span> <span class="n">subfig1</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mahal_emp_cov</span><span class="p">),</span>
                                  <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">PuBu_r</span><span class="p">,</span>
                                  <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>

<span class="n">mahal_robust_cov</span> <span class="o">=</span> <span class="n">robust_cov</span><span class="o">.</span><span class="n">mahalanobis</span><span class="p">(</span><span class="n">zz</span><span class="p">)</span>
<span class="n">mahal_robust_cov</span> <span class="o">=</span> <span class="n">mahal_robust_cov</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">robust_contour</span> <span class="o">=</span> <span class="n">subfig1</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mahal_robust_cov</span><span class="p">),</span>
                                 <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">YlOrBr_r</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dotted&#39;</span><span class="p">)</span>

<span class="n">subfig1</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="n">emp_cov_contour</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">robust_contour</span><span class="o">.</span><span class="n">collections</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">inlier_plot</span><span class="p">,</span> <span class="n">outlier_plot</span><span class="p">],</span>
               <span class="p">[</span><span class="s1">&#39;MLE dist&#39;</span><span class="p">,</span> <span class="s1">&#39;robust dist&#39;</span><span class="p">,</span> <span class="s1">&#39;inliers&#39;</span><span class="p">,</span> <span class="s1">&#39;outliers&#39;</span><span class="p">],</span>
               <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">borderaxespad</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(())</span>

</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>([], &lt;a list of 0 Text yticklabel objects&gt;)
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_30_1.png" src="../_images/03-outlier-detection_30_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">EllipticEnvelope</span>
<span class="n">ee</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">(</span><span class="n">contamination</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">ee</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
 -1  1  1  1 -1 -1  1 -1  1  1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1  1 -1  1  1]
0.104
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">EllipticEnvelope</span>
<span class="n">ee</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">(</span><span class="n">contamination</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">ee</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x7fc8da8fe198&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_32_1.png" src="../_images/03-outlier-detection_32_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KernelDensity</span>
<span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_noise</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_noise</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">line_density</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">line</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">line_density</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(-6, -2)
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_33_1.png" src="../_images/03-outlier-detection_33_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">(</span><span class="n">bandwidth</span><span class="o">=.</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_noise</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">])</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_noise</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">line_density</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">line</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">line_density</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X_noise</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(-7, 1)
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_34_1.png" src="../_images/03-outlier-detection_34_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">kde</span> <span class="o">=</span> <span class="n">KernelDensity</span><span class="p">(</span><span class="n">bandwidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">kde</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">dec</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">dec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">kde</span><span class="o">.</span><span class="n">score_samples</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">pred</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x7fc8d8ed5a90&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_37_1.png" src="../_images/03-outlier-detection_37_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">OneClassSVM</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_noise_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">oneclass</span> <span class="o">=</span> <span class="n">OneClassSVM</span><span class="p">(</span><span class="n">nu</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_noise_scaled</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">oneclass</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_noise_scaled</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dec</span> <span class="o">=</span> <span class="n">oneclass</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">dec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x7fc8d89f5e48&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_39_1.png" src="../_images/03-outlier-detection_39_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">IsolationForest</span>
<span class="n">iso</span> <span class="o">=</span> <span class="n">IsolationForest</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">iso</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
<span class="n">xlim</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">()</span>
<span class="n">ylim</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/03-outlier-detection_41_0.png" src="../_images/03-outlier-detection_41_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xlim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">xlim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">ylim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">ylim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
<span class="n">dec</span> <span class="o">=</span> <span class="n">iso</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">dec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train_noise</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Vega10</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.PathCollection at 0x7fc8d9456128&gt;
</pre></div>
</div>
<img alt="../_images/03-outlier-detection_43_1.png" src="../_images/03-outlier-detection_43_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;creditcard.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(284807, 31)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">Class</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(28480, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ee</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="c1"># =&gt; error</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ValueError</span><span class="g g-Whitespace">                                </span>Traceback (most recent call last)
<span class="nn">&lt;ipython-input-240-efde2cb2e7b3&gt;</span> in <span class="ni">&lt;module&gt;</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">ee</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="c1"># =&gt; error</span>

<span class="nn">/home/andy/checkout/scikit-learn/sklearn/covariance/outlier_detection.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y)</span>
<span class="g g-Whitespace">    </span><span class="mi">173</span> 
<span class="g g-Whitespace">    </span><span class="mi">174</span>     <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">175</span>         <span class="n">MinCovDet</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">176</span>         <span class="bp">self</span><span class="o">.</span><span class="n">threshold_</span> <span class="o">=</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">scoreatpercentile</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span>             <span class="bp">self</span><span class="o">.</span><span class="n">dist_</span><span class="p">,</span> <span class="mf">100.</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">contamination</span><span class="p">))</span>

<span class="nn">/home/andy/checkout/scikit-learn/sklearn/covariance/robust_covariance.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y)</span>
<span class="g g-Whitespace">    </span><span class="mi">617</span>             <span class="n">X</span><span class="p">,</span> <span class="n">support_fraction</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">support_fraction</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">618</span>             <span class="n">cov_computation_method</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_nonrobust_covariance</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">619</span>             <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">620</span>         <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">assume_centered</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">621</span>             <span class="n">raw_location</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>

<span class="nn">/home/andy/checkout/scikit-learn/sklearn/covariance/robust_covariance.py</span> in <span class="ni">fast_mcd</span><span class="nt">(X, support_fraction, cov_computation_method, random_state)</span>
<span class="g g-Whitespace">    </span><span class="mi">433</span>                 <span class="n">select</span><span class="o">=</span><span class="n">n_best_sub</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">434</span>                 <span class="n">cov_computation_method</span><span class="o">=</span><span class="n">cov_computation_method</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">435</span>                 <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">436</span>             <span class="n">subset_slice</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">n_best_sub</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">n_best_sub</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">437</span>             <span class="n">all_best_locations</span><span class="p">[</span><span class="n">subset_slice</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_locations_sub</span>

<span class="nn">/home/andy/checkout/scikit-learn/sklearn/covariance/robust_covariance.py</span> in <span class="ni">select_candidates</span><span class="nt">(X, n_support, n_trials, select, n_iter, verbose, cov_computation_method, random_state)</span>
<span class="g g-Whitespace">    </span><span class="mi">272</span>                     <span class="n">X</span><span class="p">,</span> <span class="n">n_support</span><span class="p">,</span> <span class="n">remaining_iterations</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">273</span>                     <span class="n">cov_computation_method</span><span class="o">=</span><span class="n">cov_computation_method</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">274</span>                     <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">275</span>     <span class="k">else</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">276</span>         <span class="c1"># perform computations from every given initial estimates</span>

<span class="nn">/home/andy/checkout/scikit-learn/sklearn/covariance/robust_covariance.py</span> in <span class="ni">_c_step</span><span class="nt">(X, n_support, random_state, remaining_iterations, initial_estimates, verbose, cov_computation_method)</span>
<span class="g g-Whitespace">    </span><span class="mi">144</span>     <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">det</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">145</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
<span class="ne">--&gt; </span><span class="mi">146</span>             <span class="s2">&quot;Singular covariance matrix. &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">147</span>             <span class="s2">&quot;Please check that the covariance matrix corresponding &quot;</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span>             <span class="s2">&quot;to the dataset is full rank and that MinCovDet is used with &quot;</span>

<span class="ne">ValueError</span>: Singular covariance matrix. Please check that the covariance matrix corresponding to the dataset is full rank and that MinCovDet is used with Gaussian-distributed data (or at least data drawn from a unimodal, symmetric distribution.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=.</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ee</span> <span class="o">=</span> <span class="n">EllipticEnvelope</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
<span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">ee</span><span class="o">.</span><span class="n">mahalanobis</span><span class="p">(</span><span class="n">X_train_pca</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.91699652177871382
</pre></div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="02-clustering-mixture-models.html" title="previous page">Clustering and Mixture Models</a>
    <a class='right-next' id="next-link" href="../04-model-evaluation/index.html" title="next page">Model Evaluation</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Andreas C. Müller<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>